Active Duration Consistency Plan (Server + Client, Shared Utility)

Context
We currently compute “active duration” only at indexing time on the server. The indexed value (sessions.active_duration_ms) is computed as the sum of per-turn spans from a user_message timestamp to the last agent_message timestamp in that turn. This works for turns that end with an agent_message, but it fails in tool-heavy turns where assistant activity happens via tool calls/outputs and reasoning without a final agent_message. The fallback path used when loading a session directly in the client does not compute active duration at all; it uses min/max timestamps as a total-span fallback for display. The result is inconsistent hourglass durations between indexed and unindexed sessions, and the “active time” definition is currently incomplete for real-world sessions that include tools and aborted turns. This plan updates both server and client to use one shared, accurate definition.

The concrete evidence for this gap comes from the session file /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl. JSONL entries are line-ordered objects with a top-level timestamp and a type. Our parsing rules treat event_msg as the authoritative conversation timeline (user_message, agent_message, agent_reasoning, token_count, turn_aborted), while response_item captures tool calls and outputs. Turn boundaries are defined by event_msg.user_message lines. In that session, the user message “let’s stick with option A...” appears as an event_msg at 2026-01-27T20:55:54.847Z. After that point, the JSONL contains no event_msg.agent_message entries in that turn, but it does include event_msg.agent_reasoning starting at 20:56:01.966Z and many response_item tool call/output entries continuing until 21:34:28.086Z. A turn_aborted event appears at 21:34:33.851Z, and a compaction entry appears around 21:35:50. This means the assistant was actively working for roughly 38 minutes after the user’s message, but the current active_duration_ms logic ignores that entire span because it only looks for agent_message. This explains why the hourglass pill shows only ~2 minutes from earlier turns and not the 30+ minute tool run the user remembers. The fix must therefore include assistant activity beyond agent_message, or the displayed duration will keep undercounting tool-heavy sessions.

To safely inspect this large JSONL without flooding the terminal, use truncated jq views. These are short, copy‑pasteable snippets that focus on a few key lines:
- Find the exact user message line and show a short preview:
  - `jq -c 'select(.type=="event_msg" and .payload.type=="user_message") | {ts:.timestamp, msg_len:((.payload.message // .payload.text // "") | tostring | length), msg:((.payload.message // .payload.text // "") | tostring | .[0:160])}' /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl | rg "let's stick with option A"`
  - If you want to cap output to a single match, add `-m 1` and optionally measure size:
    - `jq -c 'select(.type=="event_msg" and .payload.type=="user_message") | {ts:.timestamp, msg_len:((.payload.message // .payload.text // "") | tostring | length), msg:((.payload.message // .payload.text // "") | tostring | .[0:160])}' /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl | rg -m 1 "let's stick with option A" | wc -m`
    - `jq -c 'select(.type=="event_msg" and .payload.type=="user_message") | {ts:.timestamp, msg_len:((.payload.message // .payload.text // "") | tostring | length), msg:((.payload.message // .payload.text // "") | tostring | .[0:160])}' /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl | rg -m 1 "let's stick with option A" | wc -w`
- Inspect only event_msg entries around the relevant timestamps (truncate large payloads):
  - `jq -c 'select(.type==\"event_msg\") | {ts:.timestamp, subtype:.payload.type, msg_len:((.payload.message // .payload.text // \"\") | tostring | length), msg:((.payload.message // .payload.text // \"\") | tostring | .[0:160])}' /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl | rg \"2026-01-27T20:55|2026-01-27T21:34|turn_aborted\"`
- Inspect tool calls/outputs without printing full payloads:
  - `jq -c 'select(.type==\"response_item\") | {ts:.timestamp, item_type:(.payload.type // .item.type // .response_item.type), role:(.payload.role // null)}' /Users/rares/.codex/sessions/2026/01/27/rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl | rg \"2026-01-27T21:3\"`

Relevant code and how it connects
The server computes active_duration_ms in server/indexing/index.ts inside parseJsonlFile(). That value is stored in the sessions table and returned through server/indexing/tree.ts to the client, where it is used by SessionHeader, SessionsPanel, and SearchPanel to render the hourglass. The client fallback currently lives in src/features/conversation/hooks/useSession.ts and only derives startedAt/endedAt based on min/max timestamps; it does not compute active duration. The core JSONL parsing logic (turn grouping and item types) lives in src/features/conversation/parsing.ts, which is used by the client when opening an unindexed session. Any change to “active duration” therefore must be implemented in both the server’s JSONL parse path and the client’s fallback path. To avoid divergence over time, we should share a pure helper used by both environments.

The Plan
Step 1: Define the shared “active duration” concept in a single, pure utility.
Create a new file under shared/ that exports a functional-style tracker for active duration. The helper must be pure and environment-agnostic (no Node APIs), so it can be used by both server and client bundles. The tracker should expose functions to start a turn, record assistant activity timestamps, close a turn, and finalize the accumulated duration. The algorithm should be a single forward pass and constant memory: for each turn, track the user_message start time; track the latest assistant activity timestamp seen within that turn; when the next user_message arrives (or EOF), add the delta to the total if both timestamps exist and the delta is non-negative. “Assistant activity” must include agent_message and agent_reasoning events, plus tool calls and tool outputs (function_call, custom_tool_call, web_search_call, and their outputs). Do not treat turn_aborted as assistant activity; it can serve as a sentinel for “no further activity” but should not extend duration by itself. The output should be null when no valid pairs exist so the UI can show its fallback “-” or total span.

Step 2: Update server indexing to use the shared helper.
In server/indexing/index.ts, replace the ad-hoc activeDurationMs calculation in parseJsonlFile() with the shared tracker. When parsing each JSONL line, call the tracker on every user_message to start/close turns, and call the tracker for assistant activity events. The parsing should remain streaming and line-based; do not buffer entire files in memory. At end-of-file, close any active turn. Return the computed activeDurationMs from parseJsonlFile() as before, and persist it into sessions.active_duration_ms via indexSessions(). This step ensures indexed sessions reflect the new definition.

Step 3: Update client fallback to compute active duration using the same helper.
In src/features/conversation/hooks/useSession.ts, augment buildDerivedMeta() so it computes activeDurationMs using the same shared tracker. It should not rely on DB or server data; it should traverse the parsed turns/items (from parseJsonl) and record timestamps for user turns and assistant activity. Be explicit in the mapping: ParsedItem types assistant, thought, tool_call, and tool_output should count as assistant activity for the helper; user should start a turn; meta/token_count should not count as activity. The fallback should still compute startedAt/endedAt using min/max timestamps, but the hourglass should use activeDurationMs when the indexed value is missing. This ensures unindexed sessions show the same number as indexed sessions would if they were reindexed.

Step 4: Update documentation to reflect the new definition.
The IMPLEMENTATION_GUIDE.md currently describes active_duration_ms as user_message → last agent_message per turn. Update it to clarify that the “active duration” now uses the last assistant activity in a turn, which includes tool calls/outputs and agent reasoning. Call out that the computation is shared across server indexing and client fallback, and that reindexing is required to apply the new definition to existing sessions.

Step 5: Reindex sessions.
Because the meaning of active_duration_ms changes, existing indexed sessions must be recomputed. Use the existing “Reindex” or “Clear Index + Rebuild” flows to regenerate sessions.active_duration_ms. This is required for consistency across the app after code changes.

Dependencies and ordering
Step 1 must happen before Step 2 and Step 3 so both server and client use the same helper. Step 4 should follow the code changes so the documentation matches behavior. Step 5 is required after code changes are deployed so the database reflects the updated definition.

Decisions & tradeoffs
We are choosing a shared helper over duplicating logic in server and client. The alternative (separate implementations) is simpler to wire initially but risks subtle drift in which events are counted as assistant activity. The shared helper increases upfront work slightly but provides long-term correctness. We also choose to count tool calls and tool outputs as assistant activity, which makes the hourglass reflect “time spent working” rather than “time until assistant message.” This aligns with user expectations for tool-heavy sessions but means historical data will change after reindexing. Another alternative would be to add a second metric (e.g., work_duration_ms) and keep the original active_duration_ms semantics, but that adds schema complexity and UI decisions; we accept a definition change instead.

Landmines and non-obvious details
JSONL ordering is the source of truth, and turn grouping is based on event_msg.user_message only. Be careful to treat tool calls/outputs (response_item) as assistant activity but not as turn boundaries. Also, do not count preamble activity (turn_id <= 0) as part of active duration; this is naturally avoided if the helper only starts turns on user_message. The helper should use timestamps only when parseable and ignore malformed values. The client’s parseJsonl() creates ParsedItem entries with timestamps and types; ensure the mapping of item.type to “assistant activity” is consistent with the server’s event-level detection. The UI uses activeDurationMs in multiple places (SessionHeader, SessionsPanel, SearchPanel), so any mismatch will be visible. Also, do not accidentally replace startedAt/endedAt fallback logic—those timestamps are still needed for display and sorting. Finally, any change to the shared helper must avoid Node-only APIs so it can be bundled into the frontend.

Verification
After implementing the helper and wiring it into server and client:
1) Use a known tool-heavy session (such as the rollout-2026-01-27T15-46-54-019c0135-93ac-73e2-95ad-77582bcaad9b.jsonl example) and confirm that active duration includes the tool activity span. You should see ~30–40 minutes instead of ~2 minutes.
2) Verify that indexed sessions and unindexed sessions show the same hourglass value for the same file (compare before/after reindex).
3) Confirm that active_duration_ms stays null when there is no valid user → assistant activity span, so the UI fallback continues to behave.
4) Run the usual quality checks: npm run typecheck, npm run check, and npm run mdlint (if documentation was edited).
5) Reindex and verify that /api/sessions, /api/search, and session headers all display the same active duration for the same session.

This plan is intentionally “no shortcuts”: it standardizes the definition, enforces it in both server and client, and ensures the database is recomputed so the UI stays consistent everywhere.

APPENDIX
--------
Event-driven shared metrics accumulator

Idea:
The server already computes key metrics in one streaming pass during JSONL parsing, while the client currently does a second pass after building turns. Introducing a shared event-based metrics accumulator used by both parse loops would unify metrics computation efficiently without overgeneralizing, supporting consistent definitions for startedAt, endedAt, turnCount, messageCount, activeDuration, and first user message preview.

--

Current state:
  - Server: server/indexing/index.ts parses JSONL in one streaming pass and computes started_at, ended_at, turn_count, message_count, thought_count, tool_call_count,
    meta_count, token_count_count, active_duration_ms, first_user_message in that same pass. So indexing is already “one forward pass.”
  - Client: src/features/conversation/parsing.ts does one pass to build turns. Then buildDerivedMeta in src/features/conversation/hooks/useSession.ts does a second pass
    over turns to compute preview + started/ended + turnCount (and no activeDurationMs). That’s still O(n) but not single-pass.

  Should we define a common “metrics interface”?

  - Yes, but keep it tight. A small shared, functional “metrics accumulator” is worthwhile because we now need activeDuration to be consistent across server and client,
    and we already compute many of the same metrics in both places.
  - No, don’t make a big generic “JSONL → metrics” API. Parsing and environment concerns differ between server (streamed lines) and client (parsed turns). A shared
    accumulator is the right abstraction; the parsers can adapt their own event shapes into it.

  What I’d share
  A single shared helper in shared/ that accepts event-style inputs and returns metrics:

  - recordUserMessage(ts, content) → starts turn + captures preview
  - recordAssistantActivity(ts) → updates active duration candidate
  - recordThought(ts), recordToolCall(ts), recordToolOutput(ts), recordMeta(ts), recordTokenCount(ts)
  - recordTimestamp(ts) for min/max bounds
  - finalize() returns:
      - startedAt, endedAt, turnCount, messageCount, thoughtCount, toolCallCount, metaCount, tokenCountCount, activeDurationMs, firstUserMessagePreview
      - (optional) lastUserMessageAt, lastAssistantActivityAt if you want them

  Efficiency goal

  - You can keep it one forward pass everywhere:
      - Server: call the accumulator while reading each JSONL line (already streaming).
      - Client: call it while parsing JSONL into turns (same loop as parseJsonl), then useSession can just use the returned metrics instead of re‑scanning turns.

  Is it overkill?

  - Not if scoped. This is the set of metrics we already compute in more than one place and want consistent semantics for. Anything UI‑specific (e.g. filtered counts in
    useSessionOverview) can remain separate.

--

Draft:
Here’s a draft I’d start from. It’s intentionally small and “event‑level” so both server and client can feed it during their existing single pass.

<DRAFT>

  // shared/sessionMetrics.ts
  export type SessionMetrics = {
    startedAt: string | null;
    endedAt: string | null;
    turnCount: number | null;
    messageCount: number;
    thoughtCount: number;
    toolCallCount: number;
    metaCount: number;
    tokenCountCount: number;
    activeDurationMs: number | null;
    firstUserMessage: string | null;
  };

  export type SessionMetricsOptions = {
    previewMaxChars?: number;
    previewMaxLines?: number;
  };

  export type SessionMetricsAccumulator = {
    recordTimestamp: (timestamp?: string | null) => void;
    recordUserMessage: (timestamp?: string | null, content?: string | null) => void;
    recordAssistantMessage: (timestamp?: string | null) => void;
    recordAssistantActivity: (timestamp?: string | null) => void;
    recordThought: (timestamp?: string | null) => void;
    recordToolCall: (timestamp?: string | null) => void;
    recordToolOutput: (timestamp?: string | null) => void;
    recordMeta: (timestamp?: string | null) => void;
    recordTokenCount: (timestamp?: string | null) => void;
    closeTurn: () => void;
    finalize: () => SessionMetrics;
  };

  export const createSessionMetrics = (options: SessionMetricsOptions = {}): SessionMetricsAccumulator => {
    const { previewMaxChars = 240, previewMaxLines = 6 } = options;

    let firstUserMessage: string | null = null;
    let startedAt: string | null = null;
    let endedAt: string | null = null;
    let startedAtMs: number | null = null;
    let endedAtMs: number | null = null;

    let turnCount = 0;
    let messageCount = 0;
    let thoughtCount = 0;
    let toolCallCount = 0;
    let metaCount = 0;
    let tokenCountCount = 0;

    let inTurn = false;
    let currentTurnStartMs: number | null = null;
    let lastAssistantActivityMs: number | null = null;
    let activeDurationMs = 0;
    let activeDurationPairs = 0;

    const parseTimestamp = (value?: string | null) => {
      if (!value) return null;
      const parsed = Date.parse(value);
      return Number.isFinite(parsed) ? parsed : null;
    };

    const updateBounds = (value?: string | null) => {
      if (!value) return;
      const parsed = parseTimestamp(value);
      if (parsed === null) return;
      if (startedAtMs === null || parsed < startedAtMs) {
        startedAtMs = parsed;
        startedAt = value;
      }
      if (endedAtMs === null || parsed > endedAtMs) {
        endedAtMs = parsed;
        endedAt = value;
      }
    };

    const truncatePreview = (value: string) => {
      let truncated = value.slice(0, previewMaxChars);
      const lines = truncated.split(/\r?\n/);
      if (lines.length > previewMaxLines) {
        truncated = lines.slice(0, previewMaxLines).join('\n');
      }
      return truncated;
    };

    const closeTurn = () => {
      if (!inTurn) return;
      if (currentTurnStartMs !== null && lastAssistantActivityMs !== null) {
        const diff = lastAssistantActivityMs - currentTurnStartMs;
        if (Number.isFinite(diff) && diff >= 0) {
          activeDurationMs += diff;
          activeDurationPairs += 1;
        }
      }
      inTurn = false;
      currentTurnStartMs = null;
      lastAssistantActivityMs = null;
    };

    const recordAssistantActivity = (timestamp?: string | null) => {
      updateBounds(timestamp);
      if (!inTurn) return;
      const parsed = parseTimestamp(timestamp ?? undefined);
      if (parsed !== null) lastAssistantActivityMs = parsed;
    };

    return {
      recordTimestamp: updateBounds,

      recordUserMessage: (timestamp, content) => {
        closeTurn();
        inTurn = true;
        currentTurnStartMs = parseTimestamp(timestamp ?? undefined);
        lastAssistantActivityMs = null;
        turnCount += 1;
        messageCount += 1;
        updateBounds(timestamp);
        if (!firstUserMessage && content) {
          const trimmed = content.trim();
          if (trimmed) firstUserMessage = truncatePreview(trimmed);
        }
      },

      recordAssistantMessage: (timestamp) => {
        messageCount += 1;
        recordAssistantActivity(timestamp);
      },

      recordAssistantActivity,

      recordThought: (timestamp) => {
        thoughtCount += 1;
        messageCount += 1;
        recordAssistantActivity(timestamp);
      },

      recordToolCall: (timestamp) => {
        toolCallCount += 1;
        messageCount += 1;
        recordAssistantActivity(timestamp);
      },

      recordToolOutput: (timestamp) => {
        messageCount += 1;
        recordAssistantActivity(timestamp);
      },

      recordMeta: (timestamp) => {
        metaCount += 1;
        updateBounds(timestamp);
      },

      recordTokenCount: (timestamp) => {
        tokenCountCount += 1;
        updateBounds(timestamp);
      },

      closeTurn,

      finalize: () => {
        closeTurn();
        return {
          startedAt,
          endedAt,
          turnCount: turnCount > 0 ? turnCount : null,
          messageCount,
          thoughtCount,
          toolCallCount,
          metaCount,
          tokenCountCount,
          activeDurationMs: activeDurationPairs > 0 ? activeDurationMs : null,
          firstUserMessage,
        };
      },
    };
  };

Usage sketch:

- Server (server/indexing/index.ts): create one accumulator per file; call recordTimestamp(entry.timestamp) early, then per event type call the relevant method
  (user_message, agent_message, agent_reasoning, tool call/output, meta/token_count). At EOF call finalize() and persist metrics.
- Client (src/features/conversation/parsing.ts): create accumulator at start of parseJsonl, and in the same loop where you build Turn items, call the matching record*
  methods. parseJsonl can return { turns, errors, sessionInfo, metrics }. useSession can then use those metrics directly (no second pass).
</DRAFT>

<CLOSING-ADVICE>
  Current counting semantics to preserve

  - started_at / ended_at: min/max timestamp across all JSONL lines (including session_meta, turn_context, token_count, etc.).
  - turn_count: increment only on event_msg.user_message (preamble is naturally excluded).
  - message_count: count only items we persist as messages:
      - user_message, agent_message, agent_reasoning, tool_call, tool_output
      - (Note: includes pre‑turn items because they still get turnId = 0 in the DB)
  - thought_count: increment on event_msg.agent_reasoning (only when it has text).
  - tool_call_count: increment only on tool calls (function_call, custom_tool_call, web_search_call) — not outputs.
  - meta_count: increment on session_meta and turn_context.
  - token_count_count: increment on event_msg.token_count only.
  - first_user_message: first non‑empty user_message, trimmed + truncated.
  - active_duration_ms: sum of per‑turn spans from user_message to last assistant activity in the same turn (assistant message + reasoning + tool calls + tool outputs).
    turn_aborted should not extend duration on its own.

  That’s what the shared helper needs to encode.

  ———

  ## What it would look like (draft wiring)

  ### 1) server/indexing/index.ts (parseJsonlFile)

  Add the accumulator at the top of parseJsonlFile, and feed it per entry while streaming.

  // near top of parseJsonlFile
  const metrics = createSessionMetrics({ previewMaxChars: 1000, previewMaxLines: 50 });

  // inside for-await line loop, after JSON.parse:
  metrics.recordTimestamp(entry.timestamp);

  if (entry.type === 'session_meta') {
    metrics.recordMeta(entry.timestamp);
    ...
  }

  if (entry.type === 'turn_context') {
    metrics.recordMeta(entry.timestamp);
    ...
  }

  if (entry.type === 'event_msg') {
    const payload = entry.payload ?? {};
    if (payload.type === 'user_message') {
      metrics.recordUserMessage(entry.timestamp, payload.message ?? '');
      ...
    } else if (payload.type === 'agent_message') {
      metrics.recordAssistantMessage(entry.timestamp);
      ...
    } else if (payload.type === 'agent_reasoning' && payload.text) {
      metrics.recordThought(entry.timestamp);
      ...
    } else if (payload.type === 'token_count') {
      metrics.recordTokenCount(entry.timestamp);
    }
    continue;
  }

  const isResponseItem = entry.type === 'response_item';
  const item = isResponseItem ? (entry.item ?? entry.response_item ?? entry.payload ?? {}) : entry;
  const itemType = isResponseItem ? item.type : entry.type;

  if (['function_call', 'custom_tool_call', 'web_search_call'].includes(itemType)) {
    metrics.recordToolCall(entry.timestamp);
    ...
  }

  if (['function_call_output', 'custom_tool_call_output'].includes(itemType)) {
    metrics.recordToolOutput(entry.timestamp);
    ...
  }

  At EOF:

  const metricValues = metrics.finalize();

  Then use metricValues to populate parsed.metrics and firstUserMessage, replacing the local counters.

  ### 2) src/features/conversation/parsing.ts (parseJsonl)

  Create the same accumulator at the top and feed it in the same pass you already use to build Turn[]. Then return metrics alongside turns.

  const metrics = createSessionMetrics({
    previewMaxChars: MAX_PREVIEW_CHARS,
    previewMaxLines: MAX_PREVIEW_LINES,
  });

  for (...) {
    const entry = JSON.parse(line);
    metrics.recordTimestamp(entry.timestamp);

    if (entry.type === 'event_msg') {
      const payload = entry.payload ?? {};
      if (payload.type === 'user_message') {
        metrics.recordUserMessage(entry.timestamp, payload.message ?? '');
        ...
      } else if (payload.type === 'agent_message') {
        metrics.recordAssistantMessage(entry.timestamp);
        ...
      } else if (payload.type === 'agent_reasoning' && payload.text) {
        metrics.recordThought(entry.timestamp);
        ...
      } else if (payload.type === 'token_count') {
        metrics.recordTokenCount(entry.timestamp);
        ...
      }
      continue;
    }

    if (entry.type === 'turn_context' || entry.type === 'session_meta') {
      metrics.recordMeta(entry.timestamp);
      ...
      continue;
    }

    if (['function_call', ...].includes(itemType)) {
      metrics.recordToolCall(entry.timestamp);
      ...
    }

    if (['function_call_output', ...].includes(itemType)) {
      metrics.recordToolOutput(entry.timestamp);
      ...
    }
  }

  return { turns: output, errors, sessionInfo, metrics: metrics.finalize() };

  ### 3) src/features/conversation/hooks/useSession.ts

  Use the metrics returned by parseJsonl to populate preview / startedAt / endedAt / turnCount / activeDurationMs, instead of the second pass (buildDerivedMeta).

  ———

  ## Why this matches your semantics and stays efficient

  - It’s one forward pass on server (streamed) and client (in‑memory parse), same as today.
  - It preserves the exact counts you already store in sessions (message_count, thought_count, tool_call_count, meta_count, token_count_count).
</CLOSING-ADVICE>